import os
import re
import json
import subprocess
from urllib.parse import urljoin
from datetime import datetime
from typing import List, Dict, Set, Optional, Tuple

import requests
from bs4 import BeautifulSoup, Tag

# –Ω–æ–≤—ã–π –¥–µ—Ñ–æ–ª—Ç ‚Äî –ø–æ–¥ —Ç–µ–∫—É—â—É—é –∞—Ñ–∏—à—É
AFISHA_URL = os.environ.get("AFISHA_URL", "https://puppet-minsk.by/afisha")

TELEGRAM_BOT_TOKEN = os.environ["TELEGRAM_BOT_TOKEN"]
TELEGRAM_CHAT_ID = int(os.environ["TELEGRAM_CHAT_ID"])
SEEN_FILE = os.environ.get("SEEN_FILE", "data/seen.json")
DEBUG_PARSE = "1"

def log(msg: str):
    now = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    print(f"{now} {msg}", flush=True)

def load_seen() -> Set[str]:
    if not os.path.exists(SEEN_FILE):
        return set()
    try:
        with open(SEEN_FILE, "r", encoding="utf-8") as f:
            return set(json.load(f))
    except Exception:
        return set()

def save_seen(seen: Set[str]):
    os.makedirs(os.path.dirname(SEEN_FILE), exist_ok=True)
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        json.dump(list(seen), f, ensure_ascii=False, indent=2)

def send_telegram(text: str):
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": TELEGRAM_CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True,
    }
    try:
        r = requests.post(url, json=payload, timeout=10)
        if not r.ok:
            log(f"‚ùó –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {r.text}")
    except Exception as e:
        log(f"‚ùó Telegram error: {e}")

def fetch_afisha_html() -> Optional[str]:
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:129.0) Gecko/20100101 Firefox/129.0",
        "Accept-Language": "ru,en;q=0.9",
        "Cache-Control": "no-cache",
        "Pragma": "no-cache",
    }
    try:
        resp = requests.get(AFISHA_URL, headers=headers, timeout=25)
        resp.encoding = resp.apparent_encoding or resp.encoding or "utf-8"
        return resp.text
    except Exception as e:
        log(f"‚ùó –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∞—Ñ–∏—à—É: {e}")
        return None

MONTHS_RU = {
    # –ø–æ–¥–¥–µ—Ä–∂–∏–º –∏ –ø–∞–¥–µ–∂–∏: –ù–æ—è–±—Ä—å/–ù–æ—è–±—Ä—è, –î–µ–∫–∞–±—Ä—å/–î–µ–∫–∞–±—Ä—è –∏ —Ç. –ø.
    "—è–Ω–≤–∞—Ä—è": "01", "—è–Ω–≤–∞—Ä—å": "01",
    "—Ñ–µ–≤—Ä–∞–ª—è": "02", "—Ñ–µ–≤—Ä–∞–ª—å": "02",
    "–º–∞—Ä—Ç–∞": "03", "–º–∞—Ä—Ç": "03",
    "–∞–ø—Ä–µ–ª—è": "04", "–∞–ø—Ä–µ–ª—å": "04",
    "–º–∞—è": "05", "–º–∞–π": "05",
    "–∏—é–Ω—è": "06", "–∏—é–Ω—å": "06",
    "–∏—é–ª—è": "07", "–∏—é–ª—å": "07",
    "–∞–≤–≥—É—Å—Ç–∞": "08", "–∞–≤–≥—É—Å—Ç": "08",
    "—Å–µ–Ω—Ç—è–±—Ä—è": "09", "—Å–µ–Ω—Ç—è–±—Ä—å": "09",
    "–æ–∫—Ç—è–±—Ä—è": "10", "–æ–∫—Ç—è–±—Ä—å": "10",
    "–Ω–æ—è–±—Ä—è": "11", "–Ω–æ—è–±—Ä—å": "11",
    "–¥–µ–∫–∞–±—Ä—è": "12", "–¥–µ–∫–∞–±—Ä—å": "12",
}

def _norm_space(s: str) -> str:
    if not s:
        return s
    s = s.replace("\xa0", " ").replace("\u2002", " ").replace("\u2003", " ").replace("\u2009", " ")
    s = re.sub(r"\s+", " ", s).strip()
    return s

def _extract_year_month_from_container(node: Tag) -> Optional[Tuple[str, str]]:
    """
    –ò—â–µ–º –±–ª–∏–∂–∞–π—à–µ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è —Å –∫–ª–∞—Å—Å–æ–º –≤–∏–¥–∞ item_mounth-YYYY-MM.
    """
    cur: Optional[Tag] = node
    while isinstance(cur, Tag):
        classes = " ".join(cur.get("class", []))
        m = re.search(r"item_mounth-(\d{4})-(\d{2})", classes)
        if m:
            return m.group(1), m.group(2)
        cur = cur.parent if isinstance(cur.parent, Tag) else None
    return None

def _extract_day_and_month_from_text(text: str) -> Optional[Tuple[str, Optional[str]]]:
    """
    –ò–∑ —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ '15 –ù–æ—è–±—Ä—è, –°–±' –±–µ—Ä—ë–º –¥–µ–Ω—å '15' –∏, –µ—Å–ª–∏ –µ—Å—Ç—å, —Å–ª–æ–≤–æ –º–µ—Å—è—Ü–∞ '–ù–æ—è–±—Ä—è'.
    """
    t = _norm_space(text).lower()
    # –¥–µ–Ω—å: –ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ
    m_day = re.search(r"\b(\d{1,2})\b", t)
    day = m_day.group(1) if m_day else None
    # –º–µ—Å—è—Ü: —Å–ª–æ–≤–æ –∏–∑ —Å–ª–æ–≤–∞—Ä—è (–≤ –ø–∞–¥–µ–∂–µ —Ç–æ–∂–µ –æ–∫)
    month_word = None
    for w in MONTHS_RU.keys():
        if w in t:
            month_word = w
            break
    return (day, month_word) if day else None

def parse_afisha(html: str) -> List[Dict]:
    soup = BeautifulSoup(html, "html.parser")

    results: List[Dict] = []
    items = soup.select(".afisha_listcontainer .afisha_item")

    if DEBUG_PARSE:
        log(f"üß© DEBUG: –Ω–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫ .afisha_item: {len(items)}")

    for idx, item in enumerate(items, start=1):
        if DEBUG_PARSE:
            log(f"\nüü¶ DEBUG: –∞–Ω–∞–ª–∏–∑ –∫–∞—Ä—Ç–æ—á–∫–∏ #{idx}")

        info = item.select_one(".afisha-info")
        if not info:
            if DEBUG_PARSE:
                log("  ‚ö†Ô∏è –ù–µ—Ç .afisha-info ‚Üí –ø—Ä–æ–ø—É—Å–∫")
            continue

        p_day = info.select_one(".afisha-day")
        p_time = info.select_one(".afisha-time")
        p_title = info.select_one(".afisha-title")
        a_link = item.select_one("a.afisha_item-hover[href]")

        if DEBUG_PARSE:
            log(f"  ‚Äî day:   {p_day.get_text(strip=True) if p_day else '–Ω–µ—Ç'}")
            log(f"  ‚Äî time:  {p_time.get_text(strip=True) if p_time else '–Ω–µ—Ç'}")
            log(f"  ‚Äî title: {p_title.get_text(strip=True) if p_title else '–Ω–µ—Ç'}")
            log(f"  ‚Äî link:  {a_link.get('href') if a_link else '–Ω–µ—Ç'}")

        if not (p_day and p_time and p_title and a_link):
            if DEBUG_PARSE:
                log("  ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –Ω—É–∂–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ ‚Üí –ø—Ä–æ–ø—É—Å–∫")
            continue

        # ----- —Ä–∞–∑–±–æ—Ä —Ç–µ–∫—Å—Ç–∞ -----
        day_text = p_day.get_text(" ", strip=True)
        time_text = _norm_space(p_time.get_text(" ", strip=True))
        title = _norm_space(p_title.get_text(" ", strip=True))
        href = a_link.get("href", "").strip()

        # ----- –∏—â–µ–º YYYY-MM –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ -----
        ym = _extract_year_month_from_container(item)
        if DEBUG_PARSE:
            log(f"  üîç –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä item_mounth-YYYY-MM: {ym}")

        year, month_num = ym if ym else (None, None)

        # ----- —Ä–∞–∑–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫—É ‚Äú15 –ù–æ—è–±—Ä—è, –°–±‚Äù -----
        day_month = _extract_day_and_month_from_text(day_text)
        if DEBUG_PARSE:
            log(f"  üîç –î–µ–Ω—å/–º–µ—Å—è—Ü –∏–∑ —Ç–µ–∫—Å—Ç–∞: {day_month}")

        if not day_month:
            if DEBUG_PARSE:
                log("  ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–µ–Ω—å/–º–µ—Å—è—Ü ‚Üí –ø—Ä–æ–ø—É—Å–∫")
            continue

        day_num, month_word = day_month

        # ----- –µ—Å–ª–∏ month_num –Ω–µ—Ç ‚Äî –ø—Ä–æ–±—É–µ–º —Å–ª–æ–≤–∞—Ä—å -----
        if not month_num and month_word:
            mn = MONTHS_RU.get(month_word.lower())
            if mn:
                month_num = mn
                if DEBUG_PARSE:
                    log(f"  üîß –ú–µ—Å—è—Ü –ø–æ —Å–ª–æ–≤—É '{month_word}': {month_num}")

        # ----- –µ—Å–ª–∏ –≥–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî —Å—Ç–∞–≤–∏–º —Ç–µ–∫—É—â–∏–π -----
        if not year:
            year = str(datetime.now().year)
            if DEBUG_PARSE:
                log(f"  üîß –ì–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Üí –ø–æ—Å—Ç–∞–≤–ª–µ–Ω —Ç–µ–∫—É—â–∏–π {year}")

        # ----- –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–µ–Ω—å -----
        if day_num and len(day_num) == 1:
            day_num = "0" + day_num

        if not (year and month_num and day_num):
            if DEBUG_PARSE:
                log("  ‚ùå –ù–µ —Å–æ–±—Ä–∞–ª—Å—è –ø–æ–ª–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã ‚Üí –ø—Ä–æ–ø—É—Å–∫")
            continue

        date_str = f"{day_num}.{month_num}.{year}"

        if DEBUG_PARSE:
            log(f"  üìÖ –ò—Ç–æ–≥–æ–≤–∞—è –¥–∞—Ç–∞: {date_str}")
            log(f"  ‚è∞ –í—Ä–µ–º—è:        {time_text}")

        # –∞–±—Å–æ–ª—é—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞
        url_abs = urljoin(AFISHA_URL if AFISHA_URL.endswith("/") else AFISHA_URL + "/", href)

        if DEBUG_PARSE:
            log(f"  üîó –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Å—ã–ª–∫–∞: {url_abs}")

        item_id = f"{date_str} {time_text} | {title} | {url_abs}"

        results.append(
            {
                "id": item_id,
                "date": date_str,
                "time": time_text,
                "title": title,
                "url": url_abs,
            }
        )

        if DEBUG_PARSE:
            log(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–∞—Ä—Ç–æ—á–∫–∞ ‚Üí ID: {item_id}")

    if DEBUG_PARSE:
        log(f"\nüü¢ DEBUG: –∏—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–æ–±—Ä–∞–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π: {len(results)}")

    return results